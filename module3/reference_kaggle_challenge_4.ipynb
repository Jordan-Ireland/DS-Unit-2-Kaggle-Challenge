{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O67uhlT4MExK"
   },
   "source": [
    "Lambda School Data Science, Unit 2: Predictive Modeling\n",
    "\n",
    "# Kaggle Challenge, Module 4\n",
    "\n",
    "### Objectives\n",
    "- Do **cross-validation** with independent test set\n",
    "- Use scikit-learn for **hyperparameter optimization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "59EsvYLdDHAB"
   },
   "source": [
    "### Setup\n",
    "\n",
    "#### If you're using [Anaconda](https://www.anaconda.com/distribution/) locally\n",
    "\n",
    "Install required Python packages, if you haven't already:\n",
    "\n",
    "[category_encoders](http://contrib.scikit-learn.org/categorical-encoding/), version >= 2.0  \n",
    "`conda install -c conda-forge category_encoders`\n",
    "\n",
    "[xgboost](https://xgboost.readthedocs.io/en/latest/)  \n",
    "`conda install -c conda-forge xgboost` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hwbmmgaWDNid"
   },
   "outputs": [],
   "source": [
    "# If you're in Colab...\n",
    "import os, sys\n",
    "in_colab = 'google.colab' in sys.modules\n",
    "\n",
    "if in_colab:\n",
    "    # Install required python packages:\n",
    "    # category_encoders, version >= 2.0\n",
    "    # eli5, version >= 0.9\n",
    "    # pandas-profiling, version >= 2.0\n",
    "    # plotly, version >= 4.0\n",
    "    !pip install --upgrade category_encoders eli5 pandas-profiling plotly\n",
    "    \n",
    "    # Pull files from Github repo\n",
    "    os.chdir('/content')\n",
    "    !git init .\n",
    "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge.git\n",
    "    !git pull origin master\n",
    "    \n",
    "    # Change into directory for module\n",
    "    os.chdir('module4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K3pcjj0LS4_I"
   },
   "source": [
    "## NYC\n",
    "\n",
    "We're going back to one of our **New York City** real estate datasets. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Huo510lPS4_I"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Read New York City apartment rental listing data\n",
    "df = pd.read_csv('../data/renthop-nyc.csv')\n",
    "assert df.shape == (49352, 34)\n",
    "\n",
    "# Remove the most extreme 1% prices,\n",
    "# the most extreme .1% latitudes, &\n",
    "# the most extreme .1% longitudes\n",
    "df = df[(df['price'] >= np.percentile(df['price'], 0.5)) & \n",
    "        (df['price'] <= np.percentile(df['price'], 99.5)) & \n",
    "        (df['latitude'] >= np.percentile(df['latitude'], 0.05)) & \n",
    "        (df['latitude'] < np.percentile(df['latitude'], 99.95)) &\n",
    "        (df['longitude'] >= np.percentile(df['longitude'], 0.05)) & \n",
    "        (df['longitude'] <= np.percentile(df['longitude'], 99.95))]\n",
    "\n",
    "# Do train/test split\n",
    "# Use data from April & May 2016 to train\n",
    "# Use data from June 2016 to test\n",
    "df['created'] = pd.to_datetime(df['created'], infer_datetime_format=True)\n",
    "cutoff = pd.to_datetime('2016-06-01')\n",
    "train = df[df.created < cutoff]\n",
    "test  = df[df.created >= cutoff]\n",
    "\n",
    "# Wrangle train & test sets in the same way\n",
    "def engineer_features(df):\n",
    "    \n",
    "    # Avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "        \n",
    "    # Does the apartment have a description?\n",
    "    df['description'] = df['description'].str.strip().fillna('')\n",
    "    df['has_description'] = df['description'] != ''\n",
    "\n",
    "    # How long is the description?\n",
    "    df['description_length'] = df['description'].str.len()\n",
    "\n",
    "    # How many total perks does each apartment have?\n",
    "    perk_cols = ['elevator', 'cats_allowed', 'hardwood_floors', 'dogs_allowed',\n",
    "                 'doorman', 'dishwasher', 'no_fee', 'laundry_in_building',\n",
    "                 'fitness_center', 'pre-war', 'laundry_in_unit', 'roof_deck',\n",
    "                 'outdoor_space', 'dining_room', 'high_speed_internet', 'balcony',\n",
    "                 'swimming_pool', 'new_construction', 'exclusive', 'terrace', \n",
    "                 'loft', 'garden_patio', 'common_outdoor_space', \n",
    "                 'wheelchair_access']\n",
    "    df['perk_count'] = df[perk_cols].sum(axis=1)\n",
    "\n",
    "    # Are cats or dogs allowed?\n",
    "    df['cats_or_dogs'] = (df['cats_allowed']==1) | (df['dogs_allowed']==1)\n",
    "\n",
    "    # Are cats and dogs allowed?\n",
    "    df['cats_and_dogs'] = (df['cats_allowed']==1) & (df['dogs_allowed']==1)\n",
    "\n",
    "    # Total number of rooms (beds + baths)\n",
    "    df['rooms'] = df['bedrooms'] + df['bathrooms']\n",
    "    \n",
    "    # Extract number of days elapsed in year, and drop original date feature\n",
    "    df['days'] = (df['created'] - pd.to_datetime('2016-01-01')).dt.days\n",
    "    df = df.drop(columns='created')\n",
    "\n",
    "    return df\n",
    "\n",
    "train = engineer_features(train)\n",
    "test = engineer_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6OoA5u6S4_K"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-540dd9a3a70a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas_profiling\\controller\\pandas_decorator.py\u001b[0m in \u001b[0;36mprofile_report\u001b[1;34m(df, **kwargs)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mProfileReport\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \"\"\"\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas_profiling\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, df, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;31m# Get dataset statistics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mdescription_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdescribe_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# Get sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas_profiling\\model\\describe.py\u001b[0m in \u001b[0;36mdescribe\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mThreadPool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mseries_description\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstarmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmultiprocess_1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    541\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m                 \u001b[0mseries_description\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mstarmap\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         '''\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m     def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas_profiling\n",
    "train.profile_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XwrvaIwzv2cA"
   },
   "source": [
    "## Do cross-validation with independent test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hr-Dt67Gv2cB"
   },
   "source": [
    "Let's take another look at [Sebastian Raschka's diagram of model evaluation methods.](https://sebastianraschka.com/blog/2018/model-evaluation-selection-part4.html) So far we've been using \"**train/validation/test split**\", but we have more options. \n",
    "\n",
    "Today we'll learn about \"k-fold **cross-validation** with independent test set\", for \"model selection (**hyperparameter optimization**) and performance estimation.\"\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/blog/2018/model-evaluation-selection-part4/model-eval-conclusions.jpg\" width=\"600\">\n",
    "\n",
    "<sup>Source: https://sebastianraschka.com/blog/2018/model-evaluation-selection-part4.html</sup>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ozuzFo_Pv2cB"
   },
   "source": [
    "The Scikit-Learn docs show a diagram of how k-fold cross-validation works, and explain the pros & cons of cross-validation versus train/validate/test split.\n",
    "\n",
    "#### [Scikit-Learn User Guide, 3.1 Cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "\n",
    "> When evaluating different settings (“hyperparameters”) for estimators, there is still a risk of overfitting on the test set because the parameters can be tweaked until the estimator performs optimally. This way, knowledge about the test set can “leak” into the model and evaluation metrics no longer report on generalization performance. To solve this problem, yet another part of the dataset can be held out as a so-called “validation set”: training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set.\n",
    "\n",
    "> However, **by partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets.**\n",
    "\n",
    "> **A solution to this problem is a procedure called cross-validation (CV for short). A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV.** \n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" width=\"600\">\n",
    "\n",
    "> In the basic approach, called k-fold CV, the training set is split into k smaller sets. The following procedure is followed for each of the k “folds”:\n",
    "\n",
    "> - A model is trained using $k-1$ of the folds as training data;\n",
    "> - the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n",
    "\n",
    "> The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. **This approach can be computationally expensive, but does not waste too much data (as is the case when fixing an arbitrary validation set).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o10EvckQv2cC"
   },
   "source": [
    "### cross_val_score\n",
    "\n",
    "How do we get started? According to the [Scikit-Learn User Guide](https://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics), \n",
    "\n",
    "> The simplest way to use cross-validation is to call the [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) helper function\n",
    "\n",
    "But, there's a quirk: For scikit-learn's cross-validation [**scoring**](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter), higher is better. But for regression error metrics, lower is better. So scikit-learn multiplies regression error metrics by -1 to make them negative. That's why the value of the `scoring` parameter is `'neg_mean_absolute_error'`.\n",
    "\n",
    "So, k-fold cross-validation with this dataset looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.21.2'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "de9Sc59PS4_P"
   },
   "source": [
    "#### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nlPQMrftS4_Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for 3 folds: [709.71073719 700.6319256  699.68272256]\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Condo Sales\n",
    "# target = 'SALE_PRICE'\n",
    "# high_cardinality = ['SALE_DATE', 'NEIGHBORHOOD', 'ADDRESS']\n",
    "\n",
    "# Apartment Rents\n",
    "target = 'price'\n",
    "high_cardinality = ['display_address', 'street_address', 'description']\n",
    "features = train.columns.drop([target] + high_cardinality)\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OneHotEncoder(use_cat_names=True), \n",
    "    SimpleImputer(strategy='mean'), \n",
    "    SelectKBest(f_regression, k=10), \n",
    "    Ridge(alpha=1.0)\n",
    ")\n",
    "\n",
    "k = 3\n",
    "scores = cross_val_score(pipeline, X_train, y_train, cv=k, \n",
    "                         scoring='neg_mean_absolute_error')\n",
    "print(f'MAE for {k} folds:', -scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31844,), (31844, 36))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tg3qjPPKS4_S"
   },
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CmIaezQsS4_S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for 3 folds: [392.28996182 404.92923235 388.97416404]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "features = train.columns.drop(target)\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.TargetEncoder(min_samples_leaf=1, smoothing=1), \n",
    "    SimpleImputer(strategy='median'), \n",
    "    RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42)\n",
    ")\n",
    "\n",
    "k = 3\n",
    "scores = cross_val_score(pipeline, X_train, y_train, cv=k, \n",
    "                         scoring='neg_mean_absolute_error', error_score='raise')\n",
    "print(f'MAE for {k} folds:', -scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dq-PfpGZSHJ"
   },
   "source": [
    "But the Random Forest has many hyperparameters. We mostly used the defaults, and arbitrarily chose `n_estimators`. Is it too high? Too low? Just right? How do we know?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YCubg7EbjZyT"
   },
   "outputs": [],
   "source": [
    "print('Model Hyperparameters:')\n",
    "print(pipeline.named_steps['randomforestregressor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bk6o8W7Cv2cE"
   },
   "source": [
    "\"The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\" —[Francois Chollet](https://books.google.com/books?id=dadfDwAAQBAJ&pg=PA114)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p8uKvR_pv2cG"
   },
   "source": [
    "### Validation Curve\n",
    "\n",
    "Let's try different parameter values, and visualize \"the border between underfitting and overfitting.\" \n",
    "\n",
    "Using scikit-learn, we can make [validation curves](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html), \"to determine training and test scores for varying parameter values. This is similar to grid search with one parameter.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hEIxeNXdv2cF"
   },
   "source": [
    "<img src=\"https://jakevdp.github.io/PythonDataScienceHandbook/figures/05.03-validation-curve.png\">\n",
    "\n",
    "<sup>Source: https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r3bbgaP2c3Pr"
   },
   "source": [
    "Validation curves are awesome for learning about overfitting and underfitting. (But less useful in real-world projects, because we usually want to vary more than one parameter.)\n",
    "\n",
    "For this example, let's see what happens when we vary the depth of a decision tree. (This will be faster than varying the number of estimators in a random forest.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znIz2FPQv2cG"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(), \n",
    "    DecisionTreeRegressor()\n",
    ")\n",
    "\n",
    "depth = range(1, 30, 3)\n",
    "train_scores, val_scores = validation_curve(\n",
    "    pipeline, X_train, y_train,\n",
    "    param_name='decisiontreeregressor__max_depth', \n",
    "    param_range=depth, scoring='neg_mean_absolute_error', \n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.plot(depth, np.mean(-train_scores, axis=1), color='blue', label='training error')\n",
    "plt.plot(depth, np.mean(-val_scores, axis=1), color='red', label='validation error')\n",
    "plt.xlabel('depth')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUaLgk8Pv2cJ"
   },
   "source": [
    "## Use scikit-learn for hyperparameter optimization\n",
    "\n",
    "To vary multiple hyperparameters and find their optimal values, let's try **Randomized Search CV.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AexbC7fjv2cL"
   },
   "source": [
    "#### [Scikit-Learn User Guide, 3.2 Tuning the hyper-parameters of an estimator](https://scikit-learn.org/stable/modules/grid_search.html)\n",
    "\n",
    "> Hyper-parameters are parameters that are not directly learnt within estimators. In scikit-learn they are passed as arguments to the constructor of the estimator classes. \n",
    ">\n",
    "> It is possible and recommended to search the hyper-parameter space for the best cross validation score.\n",
    ">\n",
    "> [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) exhaustively considers all parameter combinations, while [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) can sample a given number of candidates from a parameter space with a specified distribution. \n",
    ">\n",
    "> While using a grid of parameter settings is currently the most widely used method for parameter optimization, other search methods have more favourable properties. [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) implements a randomized search over parameters, where each setting is sampled from a distribution over possible parameter values.\n",
    ">\n",
    "> Specifying how parameters should be sampled is done using a dictionary. Additionally, a computation budget, being the number of sampled candidates or sampling iterations, is specified using the `n_iter` parameter. \n",
    ">\n",
    "> For each parameter, either a distribution over possible values or a list of discrete choices (which will be sampled uniformly) can be specified.\n",
    ">\n",
    "> This example uses the `scipy.stats` module, which contains many useful distributions for sampling parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VrFywYKgS4_b"
   },
   "source": [
    "#### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZtZQbJQ5v2cM"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "features = train.columns.drop([target] + high_cardinality)\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OneHotEncoder(use_cat_names=True), \n",
    "    SimpleImputer(), \n",
    "    SelectKBest(f_regression), \n",
    "    Ridge()\n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    'simpleimputer__strategy': ['mean', 'median'], \n",
    "    'selectkbest__k': randint(1, len(X_train.columns)+1), \n",
    "    'ridge__alpha': uniform(1, 10), \n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    pipeline, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=100, \n",
    "    cv=5, \n",
    "    scoring='neg_mean_absolute_error', \n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P9M-OOJltM_I"
   },
   "outputs": [],
   "source": [
    "print('Best hyperparameters', search.best_params_)\n",
    "print('Cross-validation MAE', -search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q79ipvpgqYwF"
   },
   "source": [
    "### \"Fitting X folds for each of Y candidates, totalling Z fits\" ?\n",
    "\n",
    "What did that mean? What do you think?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LyhFLUfNS4_m"
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6u2L9feWS4_q"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning, module='xgboost')\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(), \n",
    "    XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    ")\n",
    "\n",
    "# https://machinelearningmastery.com/tune-learning-rate-for-gradient-boosting-with-xgboost-in-python/\n",
    "param_distributions = {\n",
    "    'xgbregressor__n_estimators': randint(100, 1000), \n",
    "    'xgbregressor__max_depth': randint(3, 10), \n",
    "    'xgbregressor__learning_rate': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    pipeline, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=5, \n",
    "    cv=2, \n",
    "    scoring='neg_mean_absolute_error', \n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t18Wb1u3S4_s"
   },
   "outputs": [],
   "source": [
    "print('Best hyperparameters', search.best_params_)\n",
    "print('Cross-validation MAE', -search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eVuKQ7kAS4_u"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oo9-Kbx6uWM3"
   },
   "source": [
    "features = train.columns.drop(target)\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.TargetEncoder(), \n",
    "    SimpleImputer(), \n",
    "    RandomForestRegressor(random_state=42)\n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    'targetencoder__min_samples_leaf': randint(1, 1000), \n",
    "    'targetencoder__smoothing': uniform(1, 1000), \n",
    "    'simpleimputer__strategy': ['mean', 'median'], \n",
    "    'randomforestregressor__n_estimators': randint(50, 500), \n",
    "    'randomforestregressor__max_depth': [5, 10, 15, 20, None], \n",
    "    'randomforestregressor__max_features': uniform(0, 1), \n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    pipeline, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=10, \n",
    "    cv=3, \n",
    "    scoring='neg_mean_absolute_error', \n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-DoCvNZoS4_w"
   },
   "outputs": [],
   "source": [
    "print('Best hyperparameters', search.best_params_)\n",
    "print('Cross-validation MAE', -search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2tJr3YZ8xLt-"
   },
   "source": [
    "### See detailed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IGHRUlY3xF1O"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDZyu6FNyY2l"
   },
   "source": [
    "### Make predictions for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Mxh8EQmS4_2"
   },
   "outputs": [],
   "source": [
    "pipeline = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OuWqQUk_yIw4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "X_test = test[features]\n",
    "y_test = test[target]\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('Test MAE', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4sQiv9s2kOjn"
   },
   "source": [
    "## Try adjusting these hyperparameters\n",
    "\n",
    "### Tree Ensembles\n",
    "\n",
    "#### Random Forest\n",
    "- class_weight (for imbalanced classes)\n",
    "- max_depth (usually high, can try decreasing)\n",
    "- n_estimators (too low underfits, too high wastes time)\n",
    "- min_samples_leaf (increase if overfitting)\n",
    "- max_features (decrease for more diverse trees)\n",
    "\n",
    "#### XGBoost\n",
    "- scale_pos_weight (for imbalanced classes)\n",
    "- max_depth (usually low, can try increasing)\n",
    "- n_estimators (too low underfits, too high wastes time/overfits) — _I recommend using early stopping instead of cross-validation_\n",
    "- learning_rate (too low underfits, too high overfits)\n",
    "- See [Notes on Parameter Tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html) and [DART booster](https://xgboost.readthedocs.io/en/latest/tutorials/dart.html) for more ideas\n",
    "\n",
    "### Linear models\n",
    "\n",
    "#### Logistic Regression\n",
    "- C\n",
    "- class_weight (for imbalanced classes)\n",
    "- penalty\n",
    "\n",
    "#### Ridge / Lasso Regression\n",
    "- alpha\n",
    "\n",
    "#### ElasticNet Regression\n",
    "- alpha\n",
    "- l1_ratio\n",
    "\n",
    "For more explanation, see [**Aaron Gallant's 9 minute video on Ridge Regression**](https://www.youtube.com/watch?v=XK5jkedy17w)!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "reference_kaggle_challenge_4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
